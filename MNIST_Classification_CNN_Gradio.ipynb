{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safaamini/Calculatrice-MVC/blob/master/MNIST_Classification_CNN_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1whtJdsSBem"
      },
      "source": [
        "##Classification de chiffres manuscrits (MNIST)\n",
        "\n",
        "Dans ce projet, nous utilisons le dataset **MNIST**, qui contient des images de chiffres manuscrits de 0 Ã  9, pour entraÃ®ner un modÃ¨le capable de les reconnaÃ®tre automatiquement.\n",
        "\n",
        "Nous allons construire et comparer les performances dâ€™un **rÃ©seau de neurones convolutifs (CNN)**, et crÃ©er une interface interactive pour tester le modÃ¨le sur des images dessinÃ©es ou tÃ©lÃ©chargÃ©es.\n",
        "\n",
        "Lâ€™objectif est de voir :  \n",
        "- Comment un CNN peut apprendre Ã  reconnaÃ®tre des chiffres manuscrits  \n",
        "- Quelle est la prÃ©cision du modÃ¨le sur un jeu de test  \n",
        "- Comment crÃ©er une interface interactive avec **Gradio**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H1dlr4wfDvpl"
      },
      "outputs": [],
      "source": [
        "# Import des librairies nÃ©cessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crMYG8cjS39v"
      },
      "source": [
        "# Ã‰tape 1 : Chargement et prÃ©paration du dataset MNIST\n",
        "\n",
        "Nous commenÃ§ons par charger le **dataset MNIST** intÃ©grÃ© Ã  Keras, qui contient des images de chiffres manuscrits (0 Ã  9).  \n",
        "\n",
        "Ensuite, nous effectuons les Ã©tapes de prÃ©traitement nÃ©cessaires pour le CNN :  \n",
        "- **Normalisation** : les valeurs des pixels sont mises entre 0 et 1  \n",
        "- **Reshape** : adaptation de la forme des images pour le CNN `(28, 28, 1)`  \n",
        "\n",
        "Enfin, nous affichons la taille du jeu d'entraÃ®nement et du jeu de test pour vÃ©rifier que tout est correct.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAGUAeXbD1bp",
        "outputId": "57db95c6-4a70-49d6-a9f5-b8920725cafa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Taille du jeu d'entraÃ®nement : (60000, 28, 28, 1)\n",
            "Taille du jeu de test : (10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Chargement du dataset MNIST intÃ©grÃ© Ã  Keras\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalisation (mettre les valeurs entre 0 et 1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Adapter la forme des images pour le CNN : (28, 28, 1)\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(\"Taille du jeu d'entraÃ®nement :\", X_train.shape)\n",
        "print(\"Taille du jeu de test :\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "babV5RYeTGfC"
      },
      "source": [
        "# Ã‰tape 2 : CrÃ©ation du modÃ¨le CNN\n",
        "\n",
        "Dans cette Ã©tape, nous construisons notre **rÃ©seau de neurones convolutifs (CNN)** pour reconnaÃ®tre les chiffres manuscrits.\n",
        "\n",
        "### Ã‰tapes :\n",
        "\n",
        "1. **Couches convolutives** :  \n",
        "   - `Conv2D(32, (3,3))` avec activation ReLU  \n",
        "   - `Conv2D(64, (3,3))` avec activation ReLU  \n",
        "   Ces couches permettent dâ€™extraire les caractÃ©ristiques des images.  \n",
        "\n",
        "2. **Couches de pooling** : `MaxPooling2D((2,2))` pour rÃ©duire la taille des cartes de caractÃ©ristiques et limiter lâ€™overfitting.  \n",
        "\n",
        "3. **Flatten** : transformation des matrices 2D en vecteur pour les couches denses.  \n",
        "\n",
        "4. **Couches denses** :  \n",
        "   - `Dense(64, activation='relu')` pour apprendre des combinaisons de caractÃ©ristiques complexes  \n",
        "   - `Dense(10, activation='softmax')` pour produire la probabilitÃ© de chaque chiffre (0â€“9).  \n",
        "\n",
        "5. **Compilation du modÃ¨le** : utilisation de lâ€™optimiseur Adam et de la fonction de perte `sparse_categorical_crossentropy`.  \n",
        "\n",
        "Enfin, nous affichons le **rÃ©sumÃ© du modÃ¨le** pour vÃ©rifier sa structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "znrn1BcaTQht",
        "outputId": "5cd3a06c-4fe6-4715-8fbb-b8e050b8098d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚       \u001b[38;5;34m102,464\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m650\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,930\u001b[0m (476.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,930</span> (476.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121,930\u001b[0m (476.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,930</span> (476.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# CrÃ©ation du modÃ¨le CNN\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation du modÃ¨le\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Affichage du rÃ©sumÃ©\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d8Nf8QQTRNs"
      },
      "source": [
        "# Ã‰tape 3 : EntraÃ®nement du modÃ¨le CNN\n",
        "\n",
        "Nous allons maintenant **entraÃ®ner notre modÃ¨le** sur le jeu de donnÃ©es MNIST.\n",
        "\n",
        "### DÃ©tails de lâ€™entraÃ®nement :\n",
        "\n",
        "1. **DonnÃ©es dâ€™entraÃ®nement** : `X_train` et `y_train`  \n",
        "2. **Nombre dâ€™Ã©poques** : 5 (le modÃ¨le passera 5 fois sur lâ€™ensemble du jeu dâ€™entraÃ®nement)  \n",
        "3. **Validation** : utilisation de `X_test` et `y_test` pour suivre la performance du modÃ¨le sur des donnÃ©es non vues pendant lâ€™entraÃ®nement  \n",
        "\n",
        "Le rÃ©sultat de lâ€™entraÃ®nement est stockÃ© dans `history`, qui contient les **valeurs de prÃ©cision et de perte** pour chaque Ã©poque.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZfKtLOLTaVp",
        "outputId": "870e0935-cdaf-4c21-c27c-834d4adfc273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.9067 - loss: 0.3125 - val_accuracy: 0.9833 - val_loss: 0.0542\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 33ms/step - accuracy: 0.9840 - loss: 0.0505 - val_accuracy: 0.9874 - val_loss: 0.0415\n",
            "Epoch 3/5\n",
            "\u001b[1m 937/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m27s\u001b[0m 29ms/step - accuracy: 0.9893 - loss: 0.0346"
          ]
        }
      ],
      "source": [
        "# EntraÃ®nement du modÃ¨le\n",
        "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30O80zyWTb_R"
      },
      "source": [
        "# Ã‰tape 4 : Ã‰valuation du modÃ¨le\n",
        "\n",
        "AprÃ¨s lâ€™entraÃ®nement, nous Ã©valuons notre modÃ¨le sur le **jeu de test** pour mesurer sa capacitÃ© Ã  gÃ©nÃ©raliser Ã  de nouvelles donnÃ©es.\n",
        "\n",
        "### Ã‰tapes :\n",
        "\n",
        "1. **Ã‰valuation** : calcul de la perte (`loss`) et de la prÃ©cision (`accuracy`) sur `X_test` et `y_test`.  \n",
        "2. **Affichage de lâ€™accuracy** : affichage de la prÃ©cision finale sur le jeu de test.  \n",
        "3. **Visualisation de lâ€™entraÃ®nement** : tracÃ© de la progression de la prÃ©cision (`accuracy`) et de la prÃ©cision de validation (`val_accuracy`) au fil des Ã©poques pour suivre lâ€™apprentissage du modÃ¨le.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8kzMBAWThUX"
      },
      "outputs": [],
      "source": [
        "# Ã‰valuer le modÃ¨le\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"\\nâœ… Accuracy sur les donnÃ©es de test :\", test_acc)\n",
        "\n",
        "# Visualisation de la progression de l'entraÃ®nement\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(\"Ã‰volution de la prÃ©cision du modÃ¨le\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGT16DCHTjl2"
      },
      "source": [
        "# Ã‰tape 5 : Sauvegarde du modÃ¨le\n",
        "\n",
        "Une fois le modÃ¨le entraÃ®nÃ©, nous le **sauvegardons** pour pouvoir le rÃ©utiliser sans avoir Ã  le rÃ©entraÃ®ner.\n",
        "\n",
        "- Le modÃ¨le est enregistrÃ© au format **HDF5** (`.h5`) sous le nom `mnist_cnn_model.h5`.  \n",
        "- Cela permet de **charger le modÃ¨le plus tard** pour faire des prÃ©dictions ou crÃ©er une interface interactive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50XVMqR7ToOy"
      },
      "outputs": [],
      "source": [
        "# Sauvegarde du modÃ¨le entraÃ®nÃ©\n",
        "model.save(\"mnist_cnn_model.h5\")\n",
        "print(\"ModÃ¨le enregistrÃ© sous 'mnist_cnn_model.h5'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t--v7N57TrGd"
      },
      "source": [
        "# Ã‰tape 6 : PrÃ©diction sur une image individuelle\n",
        "\n",
        "Pour tester notre modÃ¨le, nous allons **sÃ©lectionner une image au hasard** dans le jeu de test et observer sa prÃ©diction.\n",
        "\n",
        "### Ã‰tapes :\n",
        "\n",
        "1. **Choix de lâ€™image** : sÃ©lection dâ€™une image de `X_test` via son index.  \n",
        "2. **Affichage** : visualisation de lâ€™image pour vÃ©rifier ce que le modÃ¨le doit prÃ©dire.  \n",
        "3. **PrÃ©diction** : passage de lâ€™image au modÃ¨le et obtention du chiffre prÃ©dit (`np.argmax`)  \n",
        "4. **Comparaison** : affichage du chiffre prÃ©dit et du chiffre rÃ©el (`y_test`) pour vÃ©rifier la prÃ©cision du modÃ¨le sur un exemple concret.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MlNQS5tTrkl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Choisir une image au hasard\n",
        "index = 0\n",
        "image = X_test[index]\n",
        "\n",
        "# Afficher l'image\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(\"Image test\")\n",
        "plt.show()\n",
        "\n",
        "# PrÃ©diction\n",
        "prediction = model.predict(np.expand_dims(image, axis=0))\n",
        "print(\"Chiffre prÃ©dit :\", np.argmax(prediction))\n",
        "print(\"Chiffre rÃ©el :\", y_test[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX8SiLkPUOnA"
      },
      "source": [
        "# Ã‰tape 7 : Installation de Gradio\n",
        "\n",
        "Pour crÃ©er une **interface interactive** permettant de tester notre modÃ¨le sur des images dessinÃ©es ou tÃ©lÃ©chargÃ©es, nous devons installer la bibliothÃ¨que **Gradio**.\n",
        "\n",
        "- La commande `!pip install gradio -q` installe Gradio dans lâ€™environnement Colab.  \n",
        "- Lâ€™option `-q` permet dâ€™effectuer lâ€™installation **en mode silencieux**, sans afficher tous les messages de progression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mxpb-H5UPMQ"
      },
      "outputs": [],
      "source": [
        "!pip install gradio -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f24cEcE3UQkv"
      },
      "source": [
        "# Ã‰tape 8 : Chargement du modÃ¨le sauvegardÃ©\n",
        "\n",
        "AprÃ¨s avoir entraÃ®nÃ© et sauvegardÃ© le modÃ¨le, nous pouvons le **recharger** pour lâ€™utiliser directement sans rÃ©entraÃ®nement.\n",
        "\n",
        "- La fonction `load_model(\"mnist_cnn_model.h5\")` permet de **restaurer le modÃ¨le complet** (architecture + poids + compilation).  \n",
        "- Cela facilite les prÃ©dictions ultÃ©rieures et la crÃ©ation dâ€™une interface interactive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00jagW3nUVQP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"mnist_cnn_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgzv3ZCfUbgg"
      },
      "source": [
        "# Ã‰tape 9 : CrÃ©ation de la fonction de prÃ©diction pour Gradio\n",
        "\n",
        "Nous dÃ©finissons une **fonction `predict_digit`** qui prend en entrÃ©e une image et renvoie les probabilitÃ©s pour chaque chiffre (0â€“9).\n",
        "\n",
        "### Ã‰tapes de la fonction :\n",
        "\n",
        "1. **VÃ©rification** : si aucune image nâ€™est fournie, on renvoie un dictionnaire avec toutes les probabilitÃ©s Ã  0.  \n",
        "2. **PrÃ©traitement** :  \n",
        "   - Redimensionnement Ã  `28x28`  \n",
        "   - Conversion en niveaux de gris  \n",
        "   - Inversion des couleurs (fond blanc, chiffre noir)  \n",
        "   - Normalisation des valeurs des pixels entre 0 et 1  \n",
        "   - Reshape pour correspondre Ã  lâ€™entrÃ©e du CNN `(1, 28, 28, 1)`  \n",
        "3. **PrÃ©diction** : passage de lâ€™image prÃ©traitÃ©e au modÃ¨le pour obtenir les probabilitÃ©s de chaque chiffre.  \n",
        "4. **Sortie** : dictionnaire `{chiffre: probabilitÃ©}` utilisÃ© par Gradio pour lâ€™affichage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b54MeXDxUiGl"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Charger ton modÃ¨le sauvegardÃ©\n",
        "model = load_model(\"mnist_cnn_model.h5\")\n",
        "\n",
        "# Fonction de prÃ©diction\n",
        "def predict_digit(image):\n",
        "    if image is None:\n",
        "        return {str(i): 0.0 for i in range(10)}\n",
        "\n",
        "    # Redimensionner et convertir en niveaux de gris\n",
        "    image = cv2.resize(image, (28, 28))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Inverser les couleurs manuellement (fond blanc, trait noir)\n",
        "    image = 255 - image\n",
        "\n",
        "    # Normaliser et reformater\n",
        "    image = image / 255.0\n",
        "    image = image.reshape(1, 28, 28, 1)\n",
        "\n",
        "    # PrÃ©dire\n",
        "    prediction = model.predict(image)\n",
        "    return {str(i): float(prediction[0][i]) for i in range(10)}\n",
        "\n",
        "# Interface Gradio simp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9VPkSsBUoMS"
      },
      "source": [
        "# Ã‰tape 10 : Compilation du modÃ¨le chargÃ©\n",
        "\n",
        "MÃªme aprÃ¨s avoir rechargÃ© le modÃ¨le depuis le fichier `.h5`, il est recommandÃ© de **recompiler le modÃ¨le** avant de lâ€™utiliser pour des prÃ©dictions ou pour lâ€™entraÃ®nement supplÃ©mentaire.\n",
        "\n",
        "- **Optimiseur** : `adam` pour mettre Ã  jour les poids du modÃ¨le  \n",
        "- **Fonction de perte** : `sparse_categorical_crossentropy`, adaptÃ©e Ã  une classification multi-classe avec des labels entiers  \n",
        "- **MÃ©trique** : `accuracy` pour suivre la prÃ©cision des prÃ©dictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cvf1XjfVUsTm"
      },
      "outputs": [],
      "source": [
        "# AprÃ¨s avoir chargÃ© ton modÃ¨le :\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSQUzo22Uv7V"
      },
      "source": [
        "# Ã‰tape 11 : CrÃ©ation de l'interface interactive avec Gradio\n",
        "\n",
        "Nous crÃ©ons une **interface utilisateur interactive** pour tester le modÃ¨le sur des images de chiffres manuscrits.\n",
        "\n",
        "### FonctionnalitÃ©s de l'interface :\n",
        "\n",
        "1. **TÃ©lÃ©chargement d'image** : l'utilisateur peut uploader une image d'un chiffre.  \n",
        "2. **PrÃ©diction** : la fonction `predict_digit` traite l'image et renvoie :  \n",
        "   - Les probabilitÃ©s pour chaque chiffre (0â€“9)  \n",
        "   - Le chiffre prÃ©dit avec le niveau de confiance  \n",
        "   - Le nombre total de prÃ©dictions effectuÃ©es (`prediction_counter`)  \n",
        "3. **Affichage des rÃ©sultats** :  \n",
        "   - `gr.Label` pour visualiser les probabilitÃ©s  \n",
        "   - `gr.Textbox` pour afficher le chiffre prÃ©dit et le compteur  \n",
        "4. **Personnalisation** : titre, description et thÃ¨me de lâ€™interface (`gradio/soft`)  \n",
        "5. **Mode live** : les prÃ©dictions se mettent Ã  jour immÃ©diatement aprÃ¨s le tÃ©lÃ©chargement de l'image  \n",
        "\n",
        "Enfin, `interface.launch(debug=True)` **dÃ©marre l'interface** et affiche un lien pour tester le modÃ¨le dans le navigateur.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4XPyg4n-U383"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Charger ton modÃ¨le\n",
        "model = load_model(\"mnist_cnn_model.h5\")\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Compteur global de prÃ©dictions\n",
        "prediction_counter = 0\n",
        "\n",
        "# Fonction de prÃ©diction\n",
        "def predict_digit(image):\n",
        "    global prediction_counter\n",
        "    if image is None:\n",
        "        return (\n",
        "            {str(i): 0.0 for i in range(10)},\n",
        "            \"Dessine un chiffre pour commencer !\",\n",
        "            f\"Total des prÃ©dictions : {prediction_counter}\"\n",
        "        )\n",
        "\n",
        "    # PrÃ©traitement de l'image\n",
        "    image = cv2.resize(image, (28, 28))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    image = 255 - image  # inversion pour fond blanc / trait noir\n",
        "    image = image / 255.0\n",
        "    image = image.reshape(1, 28, 28, 1)\n",
        "\n",
        "    # PrÃ©diction\n",
        "    prediction = model.predict(image)\n",
        "    pred_class = np.argmax(prediction)\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    prediction_counter += 1\n",
        "\n",
        "    return (\n",
        "        {str(i): float(prediction[0][i]) for i in range(10)},\n",
        "        f\"ğŸ§  Chiffre prÃ©dit : {pred_class} (Confiance : {confidence:.2%})\",\n",
        "        f\"Total des prÃ©dictions : {prediction_counter}\"\n",
        "    )\n",
        "\n",
        "# Interface Gradio â€œProâ€\n",
        "interface = gr.Interface(\n",
        "    fn=predict_digit,\n",
        "    inputs=gr.Image(\n",
        "        image_mode=\"RGB\",\n",
        "        sources=[\"upload\"],  # Permet Ã  l'utilisateur de tÃ©lÃ©charger une image\n",
        "        height=250,\n",
        "        width=250\n",
        "    ),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=3, label=\"ProbabilitÃ©s des chiffres\"),\n",
        "        gr.Textbox(label=\"RÃ©sultat\"),\n",
        "        gr.Textbox(label=\"Compteur\")\n",
        "    ],\n",
        "    title=\"ğŸ“ Classification de chiffres manuscrits MNIST\",\n",
        "    description=\"TÃ©lÃ©charge une image d'un chiffre (0â€“9) ci-dessous âœï¸\\nLe modÃ¨le CNN prÃ©dit automatiquement le chiffre avec son niveau de confiance.\",\n",
        "    theme=\"gradio/soft\",\n",
        "    live=True\n",
        ")\n",
        "\n",
        "interface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6Zk61NnVNa9"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Dans ce projet, nous avons construit un **rÃ©seau de neurones convolutifs (CNN)** capable de reconnaÃ®tre les chiffres manuscrits du dataset MNIST avec une prÃ©cision Ã©levÃ©e.  \n",
        "\n",
        "### Points clÃ©s :\n",
        "\n",
        "- Nous avons prÃ©traitÃ© les donnÃ©es : normalisation et reshape pour le CNN.  \n",
        "- Nous avons crÃ©Ã©, compilÃ© et entraÃ®nÃ© un modÃ¨le CNN avec plusieurs couches convolutives et denses.  \n",
        "- Lâ€™Ã©valuation sur le jeu de test a montrÃ© que le modÃ¨le gÃ©nÃ©ralise bien sur des donnÃ©es non vues.  \n",
        "- Nous avons sauvegardÃ© le modÃ¨le pour rÃ©utilisation et crÃ©Ã© une **interface interactive avec Gradio**, permettant de tester facilement le modÃ¨le sur des images personnalisÃ©es.  \n",
        "\n",
        "Ce projet illustre comment **le Deep Learning et les CNN** peuvent Ãªtre utilisÃ©s pour la reconnaissance dâ€™images, et montre Ã©galement comment rendre un modÃ¨le accessible Ã  lâ€™utilisateur via une interface simple et intuitive.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSVMPloa+GgiqBXvVQvE+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}